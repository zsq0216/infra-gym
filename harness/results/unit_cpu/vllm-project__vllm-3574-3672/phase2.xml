<?xml version="1.0" encoding="utf-8"?><testsuites name="pytest tests"><testsuite name="pytest" errors="4" failures="0" skipped="0" tests="4" time="3.316" timestamp="2026-02-27T11:24:24.544678+00:00" hostname="8c07f38a2591"><testcase classname="tests.engine.test_stop_strings" name="test_stop_basic" time="2.842"><error message="failed on setup with &quot;AssertionError&quot;">tests/engine/test_stop_strings.py:13: in vllm_model
    return vllm_runner(MODEL)
tests/conftest.py:302: in __init__
    self.model = LLM(
vllm/entrypoints/llm.py:112: in __init__
    self.llm_engine = LLMEngine.from_engine_args(
vllm/engine/llm_engine.py:211: in from_engine_args
    engine_config = engine_args.create_engine_config()
vllm/engine/arg_utils.py:419: in create_engine_config
    model_config = ModelConfig(
vllm/config.py:132: in __init__
    self.max_model_len = _get_and_verify_max_len(self.hf_text_config,
vllm/config.py:976: in _get_and_verify_max_len
    assert "factor" in rope_scaling
E   AssertionError</error></testcase><testcase classname="tests.engine.test_stop_strings" name="test_stop_multi_tokens" time="0.001"><error message="failed on setup with &quot;AssertionError&quot;">tests/engine/test_stop_strings.py:13: in vllm_model
    return vllm_runner(MODEL)
tests/conftest.py:302: in __init__
    self.model = LLM(
vllm/entrypoints/llm.py:112: in __init__
    self.llm_engine = LLMEngine.from_engine_args(
vllm/engine/llm_engine.py:211: in from_engine_args
    engine_config = engine_args.create_engine_config()
vllm/engine/arg_utils.py:419: in create_engine_config
    model_config = ModelConfig(
vllm/config.py:132: in __init__
    self.max_model_len = _get_and_verify_max_len(self.hf_text_config,
vllm/config.py:976: in _get_and_verify_max_len
    assert "factor" in rope_scaling
E   AssertionError</error></testcase><testcase classname="tests.engine.test_stop_strings" name="test_stop_partial_token" time="0.001"><error message="failed on setup with &quot;AssertionError&quot;">tests/engine/test_stop_strings.py:13: in vllm_model
    return vllm_runner(MODEL)
tests/conftest.py:302: in __init__
    self.model = LLM(
vllm/entrypoints/llm.py:112: in __init__
    self.llm_engine = LLMEngine.from_engine_args(
vllm/engine/llm_engine.py:211: in from_engine_args
    engine_config = engine_args.create_engine_config()
vllm/engine/arg_utils.py:419: in create_engine_config
    model_config = ModelConfig(
vllm/config.py:132: in __init__
    self.max_model_len = _get_and_verify_max_len(self.hf_text_config,
vllm/config.py:976: in _get_and_verify_max_len
    assert "factor" in rope_scaling
E   AssertionError</error></testcase><testcase classname="tests.engine.test_stop_strings" name="test_stop_token_id" time="0.001"><error message="failed on setup with &quot;AssertionError&quot;">tests/engine/test_stop_strings.py:13: in vllm_model
    return vllm_runner(MODEL)
tests/conftest.py:302: in __init__
    self.model = LLM(
vllm/entrypoints/llm.py:112: in __init__
    self.llm_engine = LLMEngine.from_engine_args(
vllm/engine/llm_engine.py:211: in from_engine_args
    engine_config = engine_args.create_engine_config()
vllm/engine/arg_utils.py:419: in create_engine_config
    model_config = ModelConfig(
vllm/config.py:132: in __init__
    self.max_model_len = _get_and_verify_max_len(self.hf_text_config,
vllm/config.py:976: in _get_and_verify_max_len
    assert "factor" in rope_scaling
E   AssertionError</error></testcase></testsuite></testsuites>