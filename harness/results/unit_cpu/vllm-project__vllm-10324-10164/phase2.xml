<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="0" failures="2" skipped="0" tests="5" time="24.252" timestamp="2026-02-27T10:28:09.302168+00:00" hostname="eb288f081fb5"><testcase classname="tests.entrypoints.test_chat_utils" name="test_resolve_content_format_hf_defined[microsoft/Phi-3.5-vision-instruct-string]" time="5.487" /><testcase classname="tests.entrypoints.test_chat_utils" name="test_resolve_content_format_hf_defined[Qwen/Qwen2-VL-2B-Instruct-openai]" time="9.956" /><testcase classname="tests.entrypoints.test_chat_utils" name="test_resolve_content_format_hf_defined[fixie-ai/ultravox-v0_3-string]" time="6.397" /><testcase classname="tests.entrypoints.test_chat_utils" name="test_resolve_content_format_hf_defined[meta-llama/Llama-3.2-11B-Vision-Instruct-openai]" time="0.951"><failure message="OSError: You are trying to access a gated repo.&#10;Make sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct.&#10;403 Client Error. (Request ID: Root=1-69a171cf-0e148a9c56b0bb9537d73c83;2cdf788e-018f-4e53-a767-b1c6b0f928fe)&#10;&#10;Cannot access gated repo for url https://hf-mirror.com/meta-llama/Llama-3.2-11B-Vision-Instruct/resolve/main/config.json.&#10;Access to model meta-llama/Llama-3.2-11B-Vision-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct to ask for access.">/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py:406: in hf_raise_for_status
    response.raise_for_status()
/usr/local/lib/python3.12/dist-packages/requests/models.py:1024: in raise_for_status
    raise HTTPError(http_error_msg, response=self)
E   requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://hf-mirror.com/meta-llama/Llama-3.2-11B-Vision-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:
/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:403: in cached_file
    resolved_file = hf_hub_download(
/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py:114: in _inner_fn
    return fn(*args, **kwargs)
/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:862: in hf_hub_download
    return _hf_hub_download_to_cache_dir(
/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:969: in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:1484: in _raise_on_head_call_error
    raise head_call_error
/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:1376: in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py:114: in _inner_fn
    return fn(*args, **kwargs)
/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:1296: in get_hf_file_metadata
    r = _request_wrapper(
/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:277: in _request_wrapper
    response = _request_wrapper(
/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:301: in _request_wrapper
    hf_raise_for_status(response)
/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py:423: in hf_raise_for_status
    raise _format(GatedRepoError, message, response) from e
E   huggingface_hub.errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-69a171cf-0e148a9c56b0bb9537d73c83;2cdf788e-018f-4e53-a767-b1c6b0f928fe)
E   
E   Cannot access gated repo for url https://hf-mirror.com/meta-llama/Llama-3.2-11B-Vision-Instruct/resolve/main/config.json.
E   Access to model meta-llama/Llama-3.2-11B-Vision-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct to ask for access.

The above exception was the direct cause of the following exception:
tests/entrypoints/test_chat_utils.py:727: in test_resolve_content_format_hf_defined
    tokenizer_group = TokenizerGroup(
vllm/transformers_utils/tokenizer_group/tokenizer_group.py:23: in __init__
    self.tokenizer = get_tokenizer(self.tokenizer_id, **tokenizer_config)
vllm/transformers_utils/tokenizer.py:144: in get_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(
/usr/local/lib/python3.12/dist-packages/transformers/models/auto/tokenization_auto.py:864: in from_pretrained
    config = AutoConfig.from_pretrained(
/usr/local/lib/python3.12/dist-packages/transformers/models/auto/configuration_auto.py:1006: in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py:570: in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py:629: in _get_config_dict
    resolved_config_file = cached_file(
/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:421: in cached_file
    raise EnvironmentError(
E   OSError: You are trying to access a gated repo.
E   Make sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct.
E   403 Client Error. (Request ID: Root=1-69a171cf-0e148a9c56b0bb9537d73c83;2cdf788e-018f-4e53-a767-b1c6b0f928fe)
E   
E   Cannot access gated repo for url https://hf-mirror.com/meta-llama/Llama-3.2-11B-Vision-Instruct/resolve/main/config.json.
E   Access to model meta-llama/Llama-3.2-11B-Vision-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct to ask for access.</failure></testcase><testcase classname="tests.entrypoints.test_chat_utils" name="test_resolve_content_format_hf_defined[meta-llama/Llama-Guard-3-1B-openai]" time="0.881"><failure message="OSError: You are trying to access a gated repo.&#10;Make sure to have access to it at https://huggingface.co/meta-llama/Llama-Guard-3-1B.&#10;403 Client Error. (Request ID: Root=1-69a171d1-45ab0c021941e6236d11e594;33a89661-69cc-408f-8d3b-3ea7de01dd4a)&#10;&#10;Cannot access gated repo for url https://hf-mirror.com/meta-llama/Llama-Guard-3-1B/resolve/main/config.json.&#10;Access to model meta-llama/Llama-Guard-3-1B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-Guard-3-1B to ask for access.">/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py:406: in hf_raise_for_status
    response.raise_for_status()
/usr/local/lib/python3.12/dist-packages/requests/models.py:1024: in raise_for_status
    raise HTTPError(http_error_msg, response=self)
E   requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://hf-mirror.com/meta-llama/Llama-Guard-3-1B/resolve/main/config.json

The above exception was the direct cause of the following exception:
/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:403: in cached_file
    resolved_file = hf_hub_download(
/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py:114: in _inner_fn
    return fn(*args, **kwargs)
/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:862: in hf_hub_download
    return _hf_hub_download_to_cache_dir(
/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:969: in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:1484: in _raise_on_head_call_error
    raise head_call_error
/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:1376: in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py:114: in _inner_fn
    return fn(*args, **kwargs)
/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:1296: in get_hf_file_metadata
    r = _request_wrapper(
/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:277: in _request_wrapper
    response = _request_wrapper(
/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:301: in _request_wrapper
    hf_raise_for_status(response)
/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py:423: in hf_raise_for_status
    raise _format(GatedRepoError, message, response) from e
E   huggingface_hub.errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-69a171d1-45ab0c021941e6236d11e594;33a89661-69cc-408f-8d3b-3ea7de01dd4a)
E   
E   Cannot access gated repo for url https://hf-mirror.com/meta-llama/Llama-Guard-3-1B/resolve/main/config.json.
E   Access to model meta-llama/Llama-Guard-3-1B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-Guard-3-1B to ask for access.

The above exception was the direct cause of the following exception:
tests/entrypoints/test_chat_utils.py:727: in test_resolve_content_format_hf_defined
    tokenizer_group = TokenizerGroup(
vllm/transformers_utils/tokenizer_group/tokenizer_group.py:23: in __init__
    self.tokenizer = get_tokenizer(self.tokenizer_id, **tokenizer_config)
vllm/transformers_utils/tokenizer.py:144: in get_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(
/usr/local/lib/python3.12/dist-packages/transformers/models/auto/tokenization_auto.py:864: in from_pretrained
    config = AutoConfig.from_pretrained(
/usr/local/lib/python3.12/dist-packages/transformers/models/auto/configuration_auto.py:1006: in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py:570: in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py:629: in _get_config_dict
    resolved_config_file = cached_file(
/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:421: in cached_file
    raise EnvironmentError(
E   OSError: You are trying to access a gated repo.
E   Make sure to have access to it at https://huggingface.co/meta-llama/Llama-Guard-3-1B.
E   403 Client Error. (Request ID: Root=1-69a171d1-45ab0c021941e6236d11e594;33a89661-69cc-408f-8d3b-3ea7de01dd4a)
E   
E   Cannot access gated repo for url https://hf-mirror.com/meta-llama/Llama-Guard-3-1B/resolve/main/config.json.
E   Access to model meta-llama/Llama-Guard-3-1B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-Guard-3-1B to ask for access.</failure></testcase></testsuite></testsuites>